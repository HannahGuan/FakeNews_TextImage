{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25173207",
   "metadata": {},
   "source": [
    "https://fakeddit.netlify.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f507dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/guanruijia/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/n4/wzs319lj251f2qslt0l8_8n40000gn/T/ipykernel_27273/3154713196.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5shf2porcyi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (564000, 16)\n",
      "\n",
      "row: Index(['author', 'clean_title', 'created_utc', 'domain', 'hasImage', 'id',\n",
      "       'image_url', 'linked_submission_id', 'num_comments', 'score',\n",
      "       'subreddit', 'title', 'upvote_ratio', '2_way_label', '3_way_label',\n",
      "       '6_way_label'],\n",
      "      dtype='object')\n",
      "\n",
      "first 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>hasImage</th>\n",
       "      <th>id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>linked_submission_id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>3_way_label</th>\n",
       "      <th>6_way_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexithymia</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>1.551641e+09</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>True</td>\n",
       "      <td>awxhir</td>\n",
       "      <td>https://external-preview.redd.it/WylDbZrnbvZdB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>My Walgreens offbrand Mucinex was engraved wit...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VIDCAs17</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>1.534727e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>True</td>\n",
       "      <td>98pbid</td>\n",
       "      <td>https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>119</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>This concerned sink with a tiny hat</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prometheus1123</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>1.496511e+09</td>\n",
       "      <td>aljazeera.com</td>\n",
       "      <td>True</td>\n",
       "      <td>6f2cy5</td>\n",
       "      <td>https://external-preview.redd.it/6fNhdbc6K1vFA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>neutralnews</td>\n",
       "      <td>Hackers leak emails from UAE ambassador to US</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>1.471341e+09</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>True</td>\n",
       "      <td>4xypkv</td>\n",
       "      <td>https://external-preview.redd.it/HLtVNhTR6wtYt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>250</td>\n",
       "      <td>photoshopbattles</td>\n",
       "      <td>PsBattle: Puppy taking in the view</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rikR3ith</td>\n",
       "      <td>i found a face in my sheet music too</td>\n",
       "      <td>1.525318e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>True</td>\n",
       "      <td>8gnet9</td>\n",
       "      <td>https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>I found a face in my sheet music too!</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                        clean_title  \\\n",
       "0     Alexithymia  my walgreens offbrand mucinex was engraved wit...   \n",
       "1        VIDCAs17                this concerned sink with a tiny hat   \n",
       "2  prometheus1123      hackers leak emails from uae ambassador to us   \n",
       "3             NaN                           puppy taking in the view   \n",
       "4       3rikR3ith               i found a face in my sheet music too   \n",
       "\n",
       "    created_utc         domain  hasImage      id  \\\n",
       "0  1.551641e+09    i.imgur.com      True  awxhir   \n",
       "1  1.534727e+09      i.redd.it      True  98pbid   \n",
       "2  1.496511e+09  aljazeera.com      True  6f2cy5   \n",
       "3  1.471341e+09    i.imgur.com      True  4xypkv   \n",
       "4  1.525318e+09      i.redd.it      True  8gnet9   \n",
       "\n",
       "                                           image_url linked_submission_id  \\\n",
       "0  https://external-preview.redd.it/WylDbZrnbvZdB...                  NaN   \n",
       "1  https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...                  NaN   \n",
       "2  https://external-preview.redd.it/6fNhdbc6K1vFA...                  NaN   \n",
       "3  https://external-preview.redd.it/HLtVNhTR6wtYt...                  NaN   \n",
       "4  https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...                  NaN   \n",
       "\n",
       "   num_comments  score          subreddit  \\\n",
       "0           2.0     12  mildlyinteresting   \n",
       "1           2.0    119         pareidolia   \n",
       "2           1.0     44        neutralnews   \n",
       "3          26.0    250   photoshopbattles   \n",
       "4           2.0     13         pareidolia   \n",
       "\n",
       "                                               title  upvote_ratio  \\\n",
       "0  My Walgreens offbrand Mucinex was engraved wit...          0.84   \n",
       "1                This concerned sink with a tiny hat          0.99   \n",
       "2      Hackers leak emails from UAE ambassador to US          0.92   \n",
       "3                 PsBattle: Puppy taking in the view          0.95   \n",
       "4              I found a face in my sheet music too!          0.84   \n",
       "\n",
       "   2_way_label  3_way_label  6_way_label  \n",
       "0            1            0            0  \n",
       "1            0            2            2  \n",
       "2            1            0            0  \n",
       "3            1            0            0  \n",
       "4            0            2            2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fakeddit/multimodal_train.tsv', sep='\\t')\n",
    "\n",
    "print(f\"Dataset: {df.shape}\")\n",
    "print(f\"\\nrow: {df.columns}\")\n",
    "print(f\"\\nfirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6951c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    https://external-preview.redd.it/WylDbZrnbvZdB...\n",
      "1    https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...\n",
      "2    https://external-preview.redd.it/6fNhdbc6K1vFA...\n",
      "3    https://external-preview.redd.it/HLtVNhTR6wtYt...\n",
      "4    https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...\n",
      "5    https://external-preview.redd.it/FQ-J9OIPFRpqi...\n",
      "6    https://preview.redd.it/l9gvkkf3jizy.jpg?width...\n",
      "7    https://external-preview.redd.it/KHisCPOGwz7cz...\n",
      "8                     http://i.imgur.com/vbveIEd%2ejpg\n",
      "9    https://preview.redd.it/31aw9wjucah11.jpg?widt...\n",
      "Name: image_url, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['image_url'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q31rmxh9lwh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, save_path, timeout=10):\n",
    "    \"\"\"\n",
    "    Download a single image from a URL and save it to the specified path.\n",
    "    \n",
    "    Args:\n",
    "        url: \n",
    "        save_path: \n",
    "        timeout: 超时时间（秒）\n",
    "    \n",
    "    Returns:\n",
    "        bool: 下载是否成功\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save(save_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"下载失败 {url}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def download_images_batch(df, save_dir='fakeddit/images', max_images=None, num_workers=5):\n",
    "    \"\"\"\n",
    "    Download images in batch from URLs in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: 包含 image_url 列的 DataFrame\n",
    "        save_dir: 保存目录\n",
    "        max_images: 最多下载多少张（None 表示全部下载）\n",
    "        num_workers: 并行下载的线程数\n",
    "    \"\"\"\n",
    "    # 创建保存目录\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 筛选有效的 URL\n",
    "    valid_df = df[df['image_url'].notna()].copy()\n",
    "    if max_images:\n",
    "        valid_df = valid_df.head(max_images)\n",
    "    \n",
    "    print(f\"准备下载 {len(valid_df)} 张图片...\")\n",
    "    \n",
    "    # 准备下载任务\n",
    "    download_tasks = []\n",
    "    for idx, row in valid_df.iterrows():\n",
    "        url = row['image_url']\n",
    "        # 使用 ID 或索引作为文件名\n",
    "        file_name = f\"{idx}.jpg\"\n",
    "        save_path = os.path.join(save_dir, file_name)\n",
    "        download_tasks.append((url, save_path))\n",
    "    \n",
    "    # 并行下载\n",
    "    successful = 0\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(tqdm(\n",
    "            executor.map(lambda x: download_image(x[0], x[1]), download_tasks),\n",
    "            total=len(download_tasks),\n",
    "            desc=\"下载进度\"\n",
    "        ))\n",
    "        successful = sum(results)\n",
    "    \n",
    "    print(f\"\\n下载完成！成功: {successful}/{len(download_tasks)}\")\n",
    "    return successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34003hfcwxa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下载失败 https://www.reddit.com/media?url=https%3A%2F%2Fexternal-preview.redd.it%2FWylDbZrnbvZdBpgfa3ntxYf17CBHndiJWHylVm2j_nY.jpg%3Fwidth%3D320%26crop%3Dsmart%26auto%3Dwebp%26s%3D449659a10792de4d55c2f27d2176fdc8bc66e72a: cannot identify image file <_io.BytesIO object at 0x1064933d0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_image('https://www.reddit.com/media?url=https%3A%2F%2Fexternal-preview.redd.it%2FWylDbZrnbvZdBpgfa3ntxYf17CBHndiJWHylVm2j_nY.jpg%3Fwidth%3D320%26crop%3Dsmart%26auto%3Dwebp%26s%3D449659a10792de4d55c2f27d2176fdc8bc66e72a', 'test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f7bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "pt8392oav6i",
   "source": "# 调试：查看响应内容\nimport urllib.parse\n\ntest_url = 'https://www.reddit.com/media?url=https%3A%2F%2Fexternal-preview.redd.it%2FWylDbZrnbvZdBpgfa3ntxYf17CBHndiJWHylVm2j_nY.jpg%3Fwidth%3D320%26crop%3Dsmart%26auto%3Dwebp%26s%3D449659a10792de4d55c2f27d2176fdc8bc66e72a'\n\n# 解析 URL，提取真实的图片地址\nif 'reddit.com/media?url=' in test_url:\n    # 从 URL 参数中提取真实图片地址\n    parsed = urllib.parse.urlparse(test_url)\n    params = urllib.parse.parse_qs(parsed.query)\n    if 'url' in params:\n        actual_url = params['url'][0]\n        print(f\"提取的真实图片 URL: {actual_url}\")\n        \n        # 尝试下载真实 URL\n        try:\n            response = requests.get(actual_url, timeout=10)\n            print(f\"状态码: {response.status_code}\")\n            print(f\"Content-Type: {response.headers.get('content-type')}\")\n            \n            if response.status_code == 200:\n                img = Image.open(BytesIO(response.content))\n                print(f\"✓ 成功！图片格式: {img.format}, 大小: {img.size}\")\n        except Exception as e:\n            print(f\"✗ 错误: {e}\")\nelse:\n    print(\"不是 Reddit 重定向 URL\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "l4b2tjpnnpg",
   "source": "# 改进的下载函数 - 处理 Reddit 重定向\nimport urllib.parse\n\ndef extract_actual_url(url):\n    \"\"\"\n    从 Reddit 重定向 URL 中提取真实的图片地址\n    \"\"\"\n    if 'reddit.com/media?url=' in url:\n        parsed = urllib.parse.urlparse(url)\n        params = urllib.parse.parse_qs(parsed.query)\n        if 'url' in params:\n            return params['url'][0]\n    return url\n\ndef download_image_improved(url, save_path, timeout=10):\n    \"\"\"\n    改进的图片下载函数，支持 Reddit 重定向\n    \n    Args:\n        url: 图片 URL（可能是 Reddit 重定向）\n        save_path: 保存路径\n        timeout: 超时时间（秒）\n    \n    Returns:\n        bool: 下载是否成功\n    \"\"\"\n    try:\n        # 提取真实 URL\n        actual_url = extract_actual_url(url)\n        \n        # 添加 User-Agent 避免被 Reddit 屏蔽\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n        }\n        \n        response = requests.get(actual_url, headers=headers, timeout=timeout)\n        response.raise_for_status()\n        \n        # 检查是否是图片\n        content_type = response.headers.get('content-type', '')\n        if not content_type.startswith('image/'):\n            print(f\"警告: {actual_url} 返回的不是图片 (Content-Type: {content_type})\")\n            return False\n        \n        # 打开并保存图片\n        img = Image.open(BytesIO(response.content))\n        img.save(save_path)\n        return True\n        \n    except Exception as e:\n        print(f\"下载失败 {url}: {str(e)}\")\n        return False\n\ndef download_images_batch_improved(df, save_dir='fakeddit/images', max_images=None, num_workers=5):\n    \"\"\"\n    改进的批量下载函数\n    \n    Args:\n        df: 包含 image_url 列的 DataFrame\n        save_dir: 保存目录\n        max_images: 最多下载多少张（None 表示全部下载）\n        num_workers: 并行下载的线程数\n    \"\"\"\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # 筛选有效的 URL\n    valid_df = df[df['image_url'].notna()].copy()\n    if max_images:\n        valid_df = valid_df.head(max_images)\n    \n    print(f\"准备下载 {len(valid_df)} 张图片...\")\n    \n    # 准备下载任务\n    download_tasks = []\n    for idx, row in valid_df.iterrows():\n        url = row['image_url']\n        # 使用 id 列作为文件名（如果存在）\n        if 'id' in row and pd.notna(row['id']):\n            file_name = f\"{row['id']}.jpg\"\n        else:\n            file_name = f\"{idx}.jpg\"\n        save_path = os.path.join(save_dir, file_name)\n        download_tasks.append((url, save_path))\n    \n    # 并行下载\n    successful = 0\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        results = list(tqdm(\n            executor.map(lambda x: download_image_improved(x[0], x[1]), download_tasks),\n            total=len(download_tasks),\n            desc=\"下载进度\"\n        ))\n        successful = sum(results)\n    \n    print(f\"\\n下载完成！成功: {successful}/{len(download_tasks)}\")\n    return successful",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7o9oegid6cs",
   "source": "# 测试改进的下载函数\ntest_url = df.iloc[0]['image_url']\nprint(f\"测试 URL: {test_url}\")\nprint(f\"真实 URL: {extract_actual_url(test_url)}\")\n\n# 测试下载\nresult = download_image_improved(test_url, 'fakeddit/test_improved.jpg')\nif result:\n    print(\"✓ 下载成功！\")\n    # 显示图片\n    img = Image.open('fakeddit/test_improved.jpg')\n    print(f\"图片大小: {img.size}\")\n    display(img)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}